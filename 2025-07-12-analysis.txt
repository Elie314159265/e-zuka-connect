# 2025/07/12 データ分析・可視化機能 開発記録

## 達成目標
- 収集した「売上データ」と「気象データ」を関連付けて分析し、店舗オーナー向けダッシュボードに可視化する。
- 「売上推移グラフ」と「客層分析グラフ」を実装する。

## 実装内容
- **サンプルデータ生成機能:**
    - 特定の店舗オーナー（あさひパン店）に紐づく、天候によって売上が変動するリアルなサンプルレシートデータを生成するデバッグ用API (`/api/debug/generate-sample-data`) を作成。
    - 属性（年代・性別）を持つ仮想顧客アカウントを作成し、それらの顧客の購買データも生成する機能を追加。
- **分析APIの拡張:**
    - `core-api`の`routers/analysis.py`に以下のエンドポイントを実装。
        - `GET /api/analysis/daily-sales`: 指定期間の日別総売上を取得する。
        - `GET /api/analysis/customer-demographics`: レシートを投稿した顧客の年代・性別をグループ化して集計する。
- **データベースモデルの拡張:**
    - `User`モデルに`age_group`と`gender`カラムを追加。
- **フロントエンドの機能拡張:**
    - お客様新規登録ページに、年代と性別の入力フォームを追加。
    - 事業者向けダッシュボードを、APIから取得した実際の分析データを表示するように修正。
        - 「売上推移」を`Recharts`ライブラリを使った折れ線グラフで描画。
        - 「主な客層」を年代別・性別の2つの円グラフで描画。

---

## 開発プロセスとデバッグの記録

### 1. サンプルデータ生成時のタイムアウト問題

- **現象:**
    - 30日分のサンプルデータを生成するAPI (`/api/debug/generate-sample-data`) を呼び出すと、レスポンスが返ってこず、タイムアウトする。
- **根本原因:**
    - APIリクエストの処理が、GKE Ingressのデフォルトタイムアウト時間（30秒）を超えていた。数百件のDB書き込みを単一の同期リクエストで実行しようとしたため、長時間応���を待機する状態になっていた。
- **解決策:**
    - **暫定対応:** まず機能を確実に動作させるため、一度に生成するデータ量を30日から7日分に減らし、処理がタイムアウト内に完了するように修正。
    - **本来あるべき姿:** このような時間のかかる処理は、APIリクエスト（同期的）としてではなく、**非同期のバックグラウンドタスク**として実装するのがベストプラクティス。将来的に`Celery`や`Cloud Tasks`などの導入を検討すべき。

### 2. 客層分析APIの集計クエリ問題

- **現象:**
    - 客層分析グラフが、年代・性別ともに「null: 1073」のような、意図しない単一のデータで表示されてしまった。
- **原因分析:**
    - `curl`でAPI (`/api/analysis/customer-demographics`) を直接叩き、レスポンスを確認。
    - `name`が`null`、`value`が巨大な数値になっており、正しくグループ化できていないことが判明。
- **根本原因:**
    - `analysis.py`に実装したSQLAlchemyのクエリに誤りがあった。
    - `join`の���方が不適切で、ユーザー属性でグループ化するつもりが、全レシートを対象に集計してしまっていた。
- **解決策:**
    - クエリを2段階に修正。
        1.  まず、分析対象の店舗で買い物をした**ユニークな顧客のIDリスト**を取得する。
        2.  次に、その顧客IDリストを使って`users`テーブルをフィルタリングし、`age_group`と`gender`でそれぞれ正しくグループ化してカウントする。
    - これにより、正しい客層データが取得できるようになった。

### 3. データベーススキーマ変更の課題と対応

- **現象:**
    - `models.py`に`age_group`などのカラムを追加してデプロイすると、`core-api`が`CrashLoopBackOff`になる。
    - ログを確認すると`UndefinedColumn`エラー（指定されたカラムがテーブルに存在しない）が発生していた。
- **根本原因:**
    - SQLAlchemyの`Base.metadata.create_all()`は、**存在しないテーブルを作成する**だけで、**��存テーブルのスキーマは変更しない**。そのため、アプリケー���ョンコードと実際のDBスキーマに不整合が生じていた。
- **解決策（手動マイグレーション）:**
    - **Alembic**のような本格的なマイグレーションツール導入が望ましいが、今回は迅速性を重視し、以下の手順で手動対応した。
        1.  `kubectl exec`で稼働中の`core-api` Podに入る。
        2.  `psycopg2`ライブラリを使ってDBに接続し、`ALTER TABLE users ADD COLUMN ...`というSQL文を直接実行して、新しいカラムを追加。
    - この経験から、今後の開発では**Alembicの導入が必須**であることが明確になった。

---

## 重要な学びと今後の改善点

- **長時間処理の非同期化:** ユーザーのリクエストに直接応答する必要のない、時間のかかる処理（データ生成、バッチ処理など）は、必ず非同期タスクとして実装する設計を初期段階から検討する。
- **複雑なSQLクエリは段階的に:** 複数のテーブルをJOINして集計するような複雑���クエリは、一度に書こうとせず、まず中間的なデータ（今回の場合、ユニークな顧客IDリスト）を取得してから、その結果を使って次の処理を行うなど、段階的に構築することでデバッグが容易になる。
- **DBマイグレーションツールの早期導入:** 手動でのスキーマ変更は、エラーが発生しやすく、また複数人での開発や環境の再現性を著しく損なう。プロジェクトの初期段階で**Alembic**を導入し、スキーマ変更をコードで体系的に管理する体制を整えるべき。

---

## 次回以降のタスク (2025/07/12時点)

### **最優先: AIによる商品プロモーション提案機能の実装**

これが本アプリケーションの最も重要なコア機能となる。

**1. データ分析バッチ処理の実装:**
   - **目的:** 定期的に全店舗のデータを横断して分析し、「特定の条件下で売れる商品」のパターンを見つけ出す。
   - **実装:**
     - Kubernetes `CronJob`として、週に1回などのスケジュールで実行されるバッチ処理を����する。
     - 処理内容:
       1. 全店舗の全レシートデータ、全ユーザーの属性データ、過去の全気象データをDBから取得する。
       2. これらのデータを組み合わせ、「天気」「気温」「曜日」「時間帯」「顧客の年代」「顧客の性別」と「購入された商品」の相関関係を分析する。
       3. 分析結果（例: `{"condition": {"weather": "sunny", "temp_gt": 25}, "item": "アイスコーヒー", "target": "20s_female"}`）を、新しい`promotion_suggestions`テーブルなどに保存する。

**2. プロモーション提案APIの実装:**
   - **目的:** 店舗オーナーがダッシュボードを開いた際に、その日の状況に応じた最適なプロモーション提案を表示する。
   - **実装:**
     - `core-api`に新しいエンドポイント `GET /api/promotions/suggestions` を作成する。
     - 処理内容:
       1. 現在の天気・気温を取得する。
       2. `promotion_suggestions`テーブルから、現在の状況に最も合致する提案を検索する。
       3. 検索結果を整形し、「今日は気温が25度を超える予報です。過去のデータから、このような日には20代女性がアイスコーヒーを購入する傾向があります。アイスコーヒーの割引クーポンを発行しませんか？」といった具体的な提案メッセージを生成して返す。

**3. フロントエンドへの実装:**
   - **目的:** ダッシュボードに「本日のプロモーション提案」のような新しいカードを追加し、APIから取得した提案を表示する。
   - **実装:**
     - ダッシュボードページに新しいコンポーネントを追加する。
     - ページ読み込み時に`/api/promotions/suggestions`を呼び出し、結果を表示する。
     - （将来的な拡張）提案の「採用する」ボタンを設置し、クリックするとクーポン発行画面に遷移するなどの導線を設ける。

### **その他・改善タスク**

- **Alembicの導入:** 開発初期段階で発生したDBスキーマ変更の課題を根本的に解決するため、データベースマイグレーションツールAlembicを導入する。
- **人気商品ランキングの実装:** 現在モックアップとなっている人気商品ランキングを、実際の売上データに基づいて集計・表示するように修正する。
- **UI/UXの継続的改善:** 全体的なデザインのブラッシュアップや、より直感的な操作性の追求。

---
## 作業終了・再開時の手順

### 作業終了時: クラスタの削除
**目的:** 不要なコストの発生を防ぐため、作業時間外はGKEクラスタを削除する。
**注意:** この操作は元に戻せません。Cloud SQLインスタンスやArtifact Registryなどの永続データは削除されません。

```bash
gcloud container clusters delete study --region=asia-northeast1 --project=your-gcp-project-id
```

### 次回作業再開時の手順

**1. GKEクラスタの再作成:**
   ```bash
   gcloud container clusters create-auto study --region=asia-northeast1 --project=your-gcp-project-id
   ```

**2. `kubectl` 認証情報の取得:**
   ```bash
   gcloud container clusters get-credentials study --region=asia-northeast1 --project=your-gcp-project-id
   ```

**3. Docker認証設定 (初回のみ):**
   ```bash
   gcloud auth configure-docker asia-northeast1-docker.pkg.dev --project=your-gcp-project-id
   ```

**4. 全Kubernetesリソースのデプロイ:**
   ```bash
   kubectl apply -k kubernetes/base
   ```

**5. 【重要】データベースのスキーマの手動適用:**
   - **背景:** 現在、DBマイグレーションツールを導入していないため、`core-api`の`models.py`で定義されたスキーマは、`users`テーブルが既に存在する場合、自動で更新されない。
   - **手順:**
     1. `core-api`のPodが正常に起動するのを待つ。
     2. 以下のコマンドを実行し、`users`テーブルに手動でカラムを追加する。
        ```bash
        # まずPod名を取得
        POD_NAME=$(kubectl get pods -n your-gcp-project-id -l app=core-api -o jsonpath='{.items[0].metadata.name}')
        
        # ALTER TABLE文を実行
        kubectl exec $POD_NAME -n your-gcp-project-id -c core-api -- python -c "import psycopg2; conn = psycopg2.connect('dbname=dbname user=user password=password host=127.0.0.1'); cur = conn.cursor(); cur.execute('ALTER TABLE users ADD COLUMN IF NOT EXISTS age_group VARCHAR, ADD COLUMN IF NOT EXISTS gender VARCHAR;'); conn.commit(); cur.close(); conn.close();"
        ```
     3. **注意:** 上記コマンドは`age_group`と`gender`カラムのみを追加する。今後`User`モデルにさらにカラムを追加した場合は、このコマンドも修正する必要がある。

**6. 動作確認とデータ再生成:**
   - 各サービスが正常に起動していることを確認する。
   - 必要に応じて、デバッグ用のAPIを呼び出して、気象データやサンプル売上データを再生成する。
     ```bash
     # 気象データの取得
     curl -X POST https://your-gcp-project-id.com/api/weather/fetch-and-store
     
     # サンプル売上データの生成
     curl -X POST https://your-gcp-project-id.com/api/debug/generate-sample-data
     curl -X POST https://your-gcp-project-id.com/api/debug/generate-customer-receipts
     ```
